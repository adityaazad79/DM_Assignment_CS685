{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Impute (or interpolate) data for the following years:  2018, 2020, 2021.  When youare imputing, assume that data for all the other 9 years are available, except this.\n",
    "- Use at least 3 different imputation techniques.\n",
    "- Impute for the following features:\n",
    "    - (1) Purpose of visit for each continent,\n",
    "    - (2) Total number ofincoming tourists per continent,\n",
    "    - (3) Number of domestic toursists per state,  and measure theaccuracy for the 3 different techniques.\n",
    "    - Explain the differences between the techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Automatically adjust the width\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of columns\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 -> Purpose of visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 -> Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purpose_2013=pd.read_excel('../data-students/TourismData-2013/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "# df_purpose_2014=pd.read_excel('../data-students/TourismData-2014/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "df_purpose_2016=pd.read_excel('../data-students/TourismData-2016/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "df_purpose_2017=pd.read_excel('../data-students/TourismData-2017/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "df_purpose_2018=pd.read_excel('../data-students/TourismData-2018/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "df_purpose_2019=pd.read_excel('../data-students/TourismData-2019/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "df_purpose_2020=pd.read_excel('../data-students/TourismData-2020/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "df_purpose_2021=pd.read_excel('../data-students/TourismData-2021/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')\n",
    "df_purpose_2022=pd.read_excel('../data-students/TourismData-2022/DISTRIBUTION OF NATIONALITY-WISE FTAs IN INDIA ACCORDING TO PURPOSE.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purpose_2013['Others'] = df_purpose_2013['Others'] + df_purpose_2013['Student']\n",
    "df_purpose_2021['Others'] = df_purpose_2021['Others'] + df_purpose_2021['Student']\n",
    "df_purpose_2022['Others'] = df_purpose_2022['Others'] + df_purpose_2022['Student']\n",
    "\n",
    "df_purpose_2013 = df_purpose_2013.drop(columns=['Student'])\n",
    "df_purpose_2021 = df_purpose_2021.drop(columns=['Student'])\n",
    "df_purpose_2022 = df_purpose_2022.drop(columns=['Student'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_purpose=[df_purpose_2013,df_purpose_2016,df_purpose_2017,df_purpose_2018,df_purpose_2019,df_purpose_2020,df_purpose_2021,df_purpose_2022]\n",
    "for df in list_purpose:\n",
    "    df.columns = df.columns.str.upper()\n",
    "    df['COUNTRY OF NATIONALITY'] = df['COUNTRY OF NATIONALITY'].str.upper()\n",
    "    df['COUNTRY OF NATIONALITY'] = df['COUNTRY OF NATIONALITY'].str.strip()\n",
    "\n",
    "list_purpose=[df_purpose_2013,df_purpose_2016,df_purpose_2017,df_purpose_2018,df_purpose_2019,df_purpose_2020,df_purpose_2021,df_purpose_2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTRY OF NATIONALITY</th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>268485.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>56.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNITED STATES OF AMERICA</td>\n",
       "      <td>1118983.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>36.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>46.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>9731.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     COUNTRY OF NATIONALITY  ARRIVALS (IN NUMBERS)  BUSINESS AND PROFESSIONAL  \\\n",
       "0             NORTH AMERICA                    NaN                        NaN   \n",
       "1                    CANADA               268485.0                        5.3   \n",
       "2  UNITED STATES OF AMERICA              1118983.0                       12.2   \n",
       "3   CENTRAL & SOUTH AMERICA                    NaN                        NaN   \n",
       "4                 ARGENTINA                 9731.0                       11.0   \n",
       "\n",
       "   LEISURE HOLIDAY AND RECREATION  MEDICAL  INDIAN DIASPORA  OTHERS  \n",
       "0                             NaN      NaN              NaN     NaN  \n",
       "1                            56.4      0.1             30.3     7.9  \n",
       "2                            36.2      0.1             46.5     5.0  \n",
       "3                             NaN      NaN              NaN     NaN  \n",
       "4                            82.7      0.1              0.4     5.8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purpose_2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=[2013,2016,2017,2018,2019,2020,2021,2022]\n",
    "df=pd.DataFrame(columns=['COUNTRY OF NATIONALITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(list_purpose)):\n",
    "#     # Convert the string data to a pandas DataFrame\n",
    "#     list_purpose[i] = list_purpose[i][list_purpose[i]['COUNTRY OF NATIONALITY'] != 'OTHERS']\n",
    "#     list_purpose[i] = list_purpose[i].reset_index(drop=True)\n",
    "\n",
    "#     # Add the continent column based on the country names\n",
    "#     continent_mapping = {\n",
    "#         \"NORTH AMERICA\": [\"CANADA\", \"UNITED STATES OF AMERICA\"],\n",
    "#         \"CENTRAL & SOUTH AMERICA\": [\"ARGENTINA\", \"BRAZIL\", \"MEXICO\"],\n",
    "#         \"WESTERN EUROPE\": [\"AUSTRIA\", \"BELGIUM\", \"DENMARK\", \"FINLAND\", \"FRANCE\", \"GERMANY\", \"GREECE\", \n",
    "#                         \"IRELAND\", \"ITALY\", \"NETHERLANDS\", \"NORWAY\", \"PORTUGAL\", \"SPAIN\", \"SWEDEN\", \n",
    "#                         \"SWITZERLAND\", \"UNITED KINGDOM\"],\n",
    "#         \"EASTERN EUROPE\": [\"CZECH REPUBLIC\", \"KAZAKHSTAN\", \"POLAND\", \"RUSSIAN FEDERATION\", \"UKRAINE\", \"HUNGARY\"],\n",
    "#         \"AFRICA\": [\"EGYPT\", \"KENYA\", \"MAURITIUS\", \"NIGERIA\", \"SOUTH AFRICA\", \"SUDAN\", \"TANZANIA\"],\n",
    "#         \"WEST ASIA\": [\"BAHRAIN\", \"IRAQ\", \"ISRAEL\", \"OMAN\", \"SAUDI ARABIA\", \"TURKEY\", \"UNITED ARAB EMIRATES\", \n",
    "#                     \"YEMEN\"],\n",
    "#         \"SOUTH ASIA\": [\"AFGHANISTAN\", \"IRAN\", \"MALDIVES\", \"NEPAL\", \"PAKISTAN\", \"BANGLADESH\", \"SRI LANKA\", \"BHUTAN\"],\n",
    "#         \"SOUTH EAST ASIA\": [\"INDONESIA\", \"MALAYSIA\", \"MYANMAR\", \"PHILIPPINES\", \"SINGAPORE\", \"THAILAND\", \"VIETNAM\"],\n",
    "#         \"EAST ASIA\": [\"REPUBLIC OF CHINA\", \"TAIWAN\", \"JAPAN\", \"REPUBLIC OF KOREA\"],\n",
    "#         \"AUSTRALASIA\": [\"AUSTRALIA\", \"NEW ZEALAND\"]\n",
    "#     }\n",
    "\n",
    "#     # Function to assign continent based on the country\n",
    "#     def assign_continent(row):\n",
    "#         for continent, countries in continent_mapping.items():\n",
    "#             if row['COUNTRY OF NATIONALITY'] in countries:\n",
    "#                 return continent\n",
    "#         return \"Unknown\"\n",
    "\n",
    "#     # Apply the function to create the new continent column\n",
    "#     # list_purpose[i]['CONTINENT'] = list_purpose[i].apply(assign_continent, axis=1)\n",
    "#     list_purpose[i].dropna(inplace=True)\n",
    "#     list_purpose[i] = list_purpose[i].reset_index(drop=True)\n",
    "\n",
    "#     list_purpose[i]=list_purpose[i][['COUNTRY OF NATIONALITY', 'ARRIVALS (IN NUMBERS)', 'BUSINESS AND PROFESSIONAL', 'LEISURE HOLIDAY AND RECREATION', 'MEDICAL', 'INDIAN DIASPORA', 'OTHERS',]]\n",
    "\n",
    "#     # list_purpose[i].columns = ['COUNTRY OF NATIONALITY', 'BUSINESS AND PROFESSIONAL '+str(years[i]), 'LEISURE HOLIDAY AND RECREATION '+str(years[i]), 'MEDICAL '+str(years[i]), 'INDIAN DIASPORA '+str(years[i]), 'OTHERS '+str(years[i])]\n",
    "#     list_purpose[i].columns = ['COUNTRY OF NATIONALITY','ARRIVALS (IN NUMBERS) '+str(years[i]), 'BUSINESS AND PROFESSIONAL '+str(years[i]), 'LEISURE HOLIDAY AND RECREATION '+str(years[i]), 'MEDICAL '+str(years[i]), 'INDIAN DIASPORA '+str(years[i]), 'OTHERS '+str(years[i])]\n",
    "\n",
    "#     # df = pd.merge(df,list_gender[i][['COUNTRY OF NATIONALITY','MALE','FEMALE']], on='COUNTRY OF NATIONALITY', how='outer')\n",
    "#     # df = pd.merge(df,list_age[i][['COUNTRY OF NATIONALITY', '0-14', '15-24',\n",
    "#     #    '25-34', '35-44', '45-54', '55-64', '65 AND ABOVE']], on='COUNTRY OF NATIONALITY', how='outer')\n",
    "#     # df = pd.merge(df,list_purpose[i][['COUNTRY OF NATIONALITY', 'BUSINESS AND PROFESSIONAL', 'LEISURE HOLIDAY AND RECREATION',\n",
    "#     #    'MEDICAL', 'INDIAN DIASPORA', 'OTHERS',]], on='COUNTRY OF NATIONALITY', how='outer')\n",
    "#     # # print(\"i : \", i)\n",
    "#     df = pd.merge(df,list_purpose[i], on='COUNTRY OF NATIONALITY', how='outer')\n",
    "#     # print(\"i : \", i)\n",
    "\n",
    "# df['CONTINENT'] = df.apply(assign_continent, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTRY OF NATIONALITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [COUNTRY OF NATIONALITY]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Sample list of years and dataframes for each year\n",
    "# years = [2020, 2021]  # Modify with actual years\n",
    "# list_purpose = [...]  # Replace with the actual list of dataframes\n",
    "\n",
    "# Country-to-continent mapping\n",
    "continent_mapping = {\n",
    "    \"NORTH AMERICA\": [\"CANADA\", \"UNITED STATES OF AMERICA\"],\n",
    "    \"CENTRAL & SOUTH AMERICA\": [\"ARGENTINA\", \"BRAZIL\", \"MEXICO\"],\n",
    "    \"WESTERN EUROPE\": [\"AUSTRIA\", \"BELGIUM\", \"DENMARK\", \"FINLAND\", \"FRANCE\", \"GERMANY\", \"GREECE\", \n",
    "                    \"IRELAND\", \"ITALY\", \"NETHERLANDS\", \"NORWAY\", \"PORTUGAL\", \"SPAIN\", \"SWEDEN\", \n",
    "                    \"SWITZERLAND\", \"UNITED KINGDOM\"],\n",
    "    \"EASTERN EUROPE\": [\"CZECH REPUBLIC\", \"KAZAKHSTAN\", \"POLAND\", \"RUSSIAN FEDERATION\", \"UKRAINE\", \"HUNGARY\"],\n",
    "    \"AFRICA\": [\"EGYPT\", \"KENYA\", \"MAURITIUS\", \"NIGERIA\", \"SOUTH AFRICA\", \"SUDAN\", \"TANZANIA\"],\n",
    "    \"WEST ASIA\": [\"BAHRAIN\", \"IRAQ\", \"ISRAEL\", \"OMAN\", \"SAUDI ARABIA\", \"TURKEY\", \"UNITED ARAB EMIRATES\", \n",
    "                \"YEMEN\"],\n",
    "    \"SOUTH ASIA\": [\"AFGHANISTAN\", \"IRAN\", \"MALDIVES\", \"NEPAL\", \"PAKISTAN\", \"BANGLADESH\", \"SRI LANKA\", \"BHUTAN\"],\n",
    "    \"SOUTH EAST ASIA\": [\"INDONESIA\", \"MALAYSIA\", \"MYANMAR\", \"PHILIPPINES\", \"SINGAPORE\", \"THAILAND\", \"VIETNAM\"],\n",
    "    \"EAST ASIA\": [\"REPUBLIC OF CHINA\", \"TAIWAN\", \"JAPAN\", \"REPUBLIC OF KOREA\"],\n",
    "    \"AUSTRALASIA\": [\"AUSTRALIA\", \"NEW ZEALAND\"]\n",
    "}\n",
    "\n",
    "# Function to assign continent based on the country\n",
    "def assign_continent(row):\n",
    "    for continent, countries in continent_mapping.items():\n",
    "        if row['COUNTRY OF NATIONALITY'] in countries:\n",
    "            return continent\n",
    "    # return \"Unknown\"\n",
    "\n",
    "# Processing each dataframe in list_purpose\n",
    "for i in range(len(list_purpose)):\n",
    "    list_purpose[i] = list_purpose[i][list_purpose[i]['COUNTRY OF NATIONALITY'] != 'OTHERS']\n",
    "    list_purpose[i].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Add year and continent columns\n",
    "    list_purpose[i]['YEAR'] = years[i]\n",
    "    list_purpose[i]['CONTINENT'] = list_purpose[i].apply(assign_continent, axis=1)\n",
    "    \n",
    "    # Select and rename relevant columns\n",
    "    list_purpose[i] = list_purpose[i][['COUNTRY OF NATIONALITY', 'CONTINENT', 'YEAR', \n",
    "                                       'ARRIVALS (IN NUMBERS)', 'BUSINESS AND PROFESSIONAL', \n",
    "                                       'LEISURE HOLIDAY AND RECREATION', 'MEDICAL', \n",
    "                                       'INDIAN DIASPORA', 'OTHERS']]\n",
    "\n",
    "# Concatenate all yearly data into a single dataframe\n",
    "df = pd.concat(list_purpose, ignore_index=True)\n",
    "\n",
    "# Aggregate data by continent and year\n",
    "continent_yearly_df = df.groupby(['CONTINENT', 'YEAR']).sum(numeric_only=True).reset_index()\n",
    "\n",
    "# View result\n",
    "# print(continent_yearly_df)\n",
    "# continent_yearly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2016</td>\n",
       "      <td>210646.0</td>\n",
       "      <td>130.18</td>\n",
       "      <td>286.66</td>\n",
       "      <td>115.32</td>\n",
       "      <td>101.18</td>\n",
       "      <td>66.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2017</td>\n",
       "      <td>146639.0</td>\n",
       "      <td>133.00</td>\n",
       "      <td>143.08</td>\n",
       "      <td>126.14</td>\n",
       "      <td>45.90</td>\n",
       "      <td>151.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2018</td>\n",
       "      <td>240262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2019</td>\n",
       "      <td>146639.0</td>\n",
       "      <td>133.00</td>\n",
       "      <td>143.08</td>\n",
       "      <td>126.14</td>\n",
       "      <td>45.90</td>\n",
       "      <td>151.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2020</td>\n",
       "      <td>61070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2021</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2022</td>\n",
       "      <td>149541.0</td>\n",
       "      <td>165.30</td>\n",
       "      <td>170.80</td>\n",
       "      <td>121.90</td>\n",
       "      <td>65.00</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALASIA</td>\n",
       "      <td>2016</td>\n",
       "      <td>344542.0</td>\n",
       "      <td>18.85</td>\n",
       "      <td>98.58</td>\n",
       "      <td>0.11</td>\n",
       "      <td>75.32</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AUSTRALASIA</td>\n",
       "      <td>2017</td>\n",
       "      <td>103411.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>88.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>70.10</td>\n",
       "      <td>30.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUSTRALASIA</td>\n",
       "      <td>2018</td>\n",
       "      <td>407150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AUSTRALASIA</td>\n",
       "      <td>2019</td>\n",
       "      <td>103411.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>88.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>70.10</td>\n",
       "      <td>30.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AUSTRALASIA</td>\n",
       "      <td>2020</td>\n",
       "      <td>103411.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AUSTRALASIA</td>\n",
       "      <td>2021</td>\n",
       "      <td>38361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AUSTRALASIA</td>\n",
       "      <td>2022</td>\n",
       "      <td>431872.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>54.60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>84.10</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2013</td>\n",
       "      <td>43272.0</td>\n",
       "      <td>53.10</td>\n",
       "      <td>222.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.10</td>\n",
       "      <td>22.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2016</td>\n",
       "      <td>49286.0</td>\n",
       "      <td>48.27</td>\n",
       "      <td>236.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11.12</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2017</td>\n",
       "      <td>59032.0</td>\n",
       "      <td>62.08</td>\n",
       "      <td>208.79</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.72</td>\n",
       "      <td>24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2018</td>\n",
       "      <td>62833.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2019</td>\n",
       "      <td>59032.0</td>\n",
       "      <td>62.08</td>\n",
       "      <td>208.79</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.72</td>\n",
       "      <td>24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2020</td>\n",
       "      <td>16966.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2021</td>\n",
       "      <td>3444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CENTRAL &amp; SOUTH AMERICA</td>\n",
       "      <td>2022</td>\n",
       "      <td>25936.0</td>\n",
       "      <td>81.80</td>\n",
       "      <td>176.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.80</td>\n",
       "      <td>32.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>2016</td>\n",
       "      <td>613563.0</td>\n",
       "      <td>184.67</td>\n",
       "      <td>194.70</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.90</td>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>2017</td>\n",
       "      <td>129048.0</td>\n",
       "      <td>172.50</td>\n",
       "      <td>210.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>2018</td>\n",
       "      <td>717997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>2019</td>\n",
       "      <td>129048.0</td>\n",
       "      <td>172.50</td>\n",
       "      <td>210.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>2020</td>\n",
       "      <td>129048.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>2021</td>\n",
       "      <td>32190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>2022</td>\n",
       "      <td>125381.0</td>\n",
       "      <td>174.70</td>\n",
       "      <td>41.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30.00</td>\n",
       "      <td>53.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>2016</td>\n",
       "      <td>314080.0</td>\n",
       "      <td>118.53</td>\n",
       "      <td>446.61</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.69</td>\n",
       "      <td>13.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>2017</td>\n",
       "      <td>353261.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>407.69</td>\n",
       "      <td>3.12</td>\n",
       "      <td>14.70</td>\n",
       "      <td>65.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>2018</td>\n",
       "      <td>356052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>2019</td>\n",
       "      <td>353261.0</td>\n",
       "      <td>109.04</td>\n",
       "      <td>407.69</td>\n",
       "      <td>3.12</td>\n",
       "      <td>14.70</td>\n",
       "      <td>65.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>2020</td>\n",
       "      <td>137435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>2021</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>2022</td>\n",
       "      <td>143371.0</td>\n",
       "      <td>148.40</td>\n",
       "      <td>340.80</td>\n",
       "      <td>7.10</td>\n",
       "      <td>26.10</td>\n",
       "      <td>77.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2013</td>\n",
       "      <td>1387468.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>92.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>76.80</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2016</td>\n",
       "      <td>1614178.0</td>\n",
       "      <td>16.44</td>\n",
       "      <td>110.62</td>\n",
       "      <td>0.14</td>\n",
       "      <td>65.49</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2017</td>\n",
       "      <td>1863891.0</td>\n",
       "      <td>16.06</td>\n",
       "      <td>89.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>50.97</td>\n",
       "      <td>43.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2018</td>\n",
       "      <td>1807718.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2019</td>\n",
       "      <td>1863891.0</td>\n",
       "      <td>16.06</td>\n",
       "      <td>89.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>50.97</td>\n",
       "      <td>43.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2020</td>\n",
       "      <td>516960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2021</td>\n",
       "      <td>510297.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>2022</td>\n",
       "      <td>1692658.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>47.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>89.60</td>\n",
       "      <td>56.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>2016</td>\n",
       "      <td>2194555.0</td>\n",
       "      <td>58.30</td>\n",
       "      <td>438.16</td>\n",
       "      <td>136.08</td>\n",
       "      <td>54.09</td>\n",
       "      <td>113.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>2017</td>\n",
       "      <td>750061.0</td>\n",
       "      <td>68.80</td>\n",
       "      <td>429.80</td>\n",
       "      <td>132.80</td>\n",
       "      <td>39.30</td>\n",
       "      <td>129.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>2018</td>\n",
       "      <td>3104422.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>2019</td>\n",
       "      <td>750061.0</td>\n",
       "      <td>68.80</td>\n",
       "      <td>429.80</td>\n",
       "      <td>132.80</td>\n",
       "      <td>39.30</td>\n",
       "      <td>129.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>2020</td>\n",
       "      <td>750061.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>2021</td>\n",
       "      <td>398722.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>2022</td>\n",
       "      <td>1723016.0</td>\n",
       "      <td>65.30</td>\n",
       "      <td>210.60</td>\n",
       "      <td>44.70</td>\n",
       "      <td>18.20</td>\n",
       "      <td>461.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>2016</td>\n",
       "      <td>741192.0</td>\n",
       "      <td>116.02</td>\n",
       "      <td>460.40</td>\n",
       "      <td>4.12</td>\n",
       "      <td>72.73</td>\n",
       "      <td>46.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>2017</td>\n",
       "      <td>228236.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>478.70</td>\n",
       "      <td>6.30</td>\n",
       "      <td>43.70</td>\n",
       "      <td>80.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>2018</td>\n",
       "      <td>876586.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>2019</td>\n",
       "      <td>228236.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>478.70</td>\n",
       "      <td>6.30</td>\n",
       "      <td>43.70</td>\n",
       "      <td>80.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>2020</td>\n",
       "      <td>228236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>2021</td>\n",
       "      <td>37852.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SOUTH EAST ASIA</td>\n",
       "      <td>2022</td>\n",
       "      <td>408762.0</td>\n",
       "      <td>83.70</td>\n",
       "      <td>344.80</td>\n",
       "      <td>23.00</td>\n",
       "      <td>44.60</td>\n",
       "      <td>203.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>WEST ASIA</td>\n",
       "      <td>2016</td>\n",
       "      <td>408243.0</td>\n",
       "      <td>94.55</td>\n",
       "      <td>506.18</td>\n",
       "      <td>134.29</td>\n",
       "      <td>28.78</td>\n",
       "      <td>36.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>WEST ASIA</td>\n",
       "      <td>2017</td>\n",
       "      <td>88671.0</td>\n",
       "      <td>94.60</td>\n",
       "      <td>421.60</td>\n",
       "      <td>211.60</td>\n",
       "      <td>33.20</td>\n",
       "      <td>38.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>WEST ASIA</td>\n",
       "      <td>2018</td>\n",
       "      <td>407919.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>WEST ASIA</td>\n",
       "      <td>2019</td>\n",
       "      <td>88671.0</td>\n",
       "      <td>94.60</td>\n",
       "      <td>421.60</td>\n",
       "      <td>211.60</td>\n",
       "      <td>33.20</td>\n",
       "      <td>38.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>WEST ASIA</td>\n",
       "      <td>2020</td>\n",
       "      <td>88671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>WEST ASIA</td>\n",
       "      <td>2021</td>\n",
       "      <td>47675.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>WEST ASIA</td>\n",
       "      <td>2022</td>\n",
       "      <td>239361.0</td>\n",
       "      <td>85.90</td>\n",
       "      <td>321.50</td>\n",
       "      <td>193.20</td>\n",
       "      <td>26.50</td>\n",
       "      <td>172.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2013</td>\n",
       "      <td>1851052.0</td>\n",
       "      <td>386.20</td>\n",
       "      <td>893.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>199.90</td>\n",
       "      <td>119.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016141.0</td>\n",
       "      <td>394.31</td>\n",
       "      <td>925.19</td>\n",
       "      <td>1.20</td>\n",
       "      <td>235.69</td>\n",
       "      <td>43.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2017</td>\n",
       "      <td>2159027.0</td>\n",
       "      <td>355.45</td>\n",
       "      <td>761.72</td>\n",
       "      <td>1.86</td>\n",
       "      <td>229.37</td>\n",
       "      <td>251.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2018</td>\n",
       "      <td>2228239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2019</td>\n",
       "      <td>2159027.0</td>\n",
       "      <td>355.45</td>\n",
       "      <td>761.72</td>\n",
       "      <td>1.86</td>\n",
       "      <td>229.37</td>\n",
       "      <td>251.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2020</td>\n",
       "      <td>619678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2021</td>\n",
       "      <td>333083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>2022</td>\n",
       "      <td>1289865.0</td>\n",
       "      <td>329.30</td>\n",
       "      <td>524.90</td>\n",
       "      <td>5.40</td>\n",
       "      <td>343.60</td>\n",
       "      <td>397.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CONTINENT  YEAR  ARRIVALS (IN NUMBERS)  \\\n",
       "0                    AFRICA  2016               210646.0   \n",
       "1                    AFRICA  2017               146639.0   \n",
       "2                    AFRICA  2018               240262.0   \n",
       "3                    AFRICA  2019               146639.0   \n",
       "4                    AFRICA  2020                61070.0   \n",
       "5                    AFRICA  2021                39827.0   \n",
       "6                    AFRICA  2022               149541.0   \n",
       "7               AUSTRALASIA  2016               344542.0   \n",
       "8               AUSTRALASIA  2017               103411.0   \n",
       "9               AUSTRALASIA  2018               407150.0   \n",
       "10              AUSTRALASIA  2019               103411.0   \n",
       "11              AUSTRALASIA  2020               103411.0   \n",
       "12              AUSTRALASIA  2021                38361.0   \n",
       "13              AUSTRALASIA  2022               431872.0   \n",
       "14  CENTRAL & SOUTH AMERICA  2013                43272.0   \n",
       "15  CENTRAL & SOUTH AMERICA  2016                49286.0   \n",
       "16  CENTRAL & SOUTH AMERICA  2017                59032.0   \n",
       "17  CENTRAL & SOUTH AMERICA  2018                62833.0   \n",
       "18  CENTRAL & SOUTH AMERICA  2019                59032.0   \n",
       "19  CENTRAL & SOUTH AMERICA  2020                16966.0   \n",
       "20  CENTRAL & SOUTH AMERICA  2021                 3444.0   \n",
       "21  CENTRAL & SOUTH AMERICA  2022                25936.0   \n",
       "22                EAST ASIA  2016               613563.0   \n",
       "23                EAST ASIA  2017               129048.0   \n",
       "24                EAST ASIA  2018               717997.0   \n",
       "25                EAST ASIA  2019               129048.0   \n",
       "26                EAST ASIA  2020               129048.0   \n",
       "27                EAST ASIA  2021                32190.0   \n",
       "28                EAST ASIA  2022               125381.0   \n",
       "29           EASTERN EUROPE  2016               314080.0   \n",
       "30           EASTERN EUROPE  2017               353261.0   \n",
       "31           EASTERN EUROPE  2018               356052.0   \n",
       "32           EASTERN EUROPE  2019               353261.0   \n",
       "33           EASTERN EUROPE  2020               137435.0   \n",
       "34           EASTERN EUROPE  2021                29239.0   \n",
       "35           EASTERN EUROPE  2022               143371.0   \n",
       "36            NORTH AMERICA  2013              1387468.0   \n",
       "37            NORTH AMERICA  2016              1614178.0   \n",
       "38            NORTH AMERICA  2017              1863891.0   \n",
       "39            NORTH AMERICA  2018              1807718.0   \n",
       "40            NORTH AMERICA  2019              1863891.0   \n",
       "41            NORTH AMERICA  2020               516960.0   \n",
       "42            NORTH AMERICA  2021               510297.0   \n",
       "43            NORTH AMERICA  2022              1692658.0   \n",
       "44               SOUTH ASIA  2016              2194555.0   \n",
       "45               SOUTH ASIA  2017               750061.0   \n",
       "46               SOUTH ASIA  2018              3104422.0   \n",
       "47               SOUTH ASIA  2019               750061.0   \n",
       "48               SOUTH ASIA  2020               750061.0   \n",
       "49               SOUTH ASIA  2021               398722.0   \n",
       "50               SOUTH ASIA  2022              1723016.0   \n",
       "51          SOUTH EAST ASIA  2016               741192.0   \n",
       "52          SOUTH EAST ASIA  2017               228236.0   \n",
       "53          SOUTH EAST ASIA  2018               876586.0   \n",
       "54          SOUTH EAST ASIA  2019               228236.0   \n",
       "55          SOUTH EAST ASIA  2020               228236.0   \n",
       "56          SOUTH EAST ASIA  2021                37852.0   \n",
       "57          SOUTH EAST ASIA  2022               408762.0   \n",
       "58                WEST ASIA  2016               408243.0   \n",
       "59                WEST ASIA  2017                88671.0   \n",
       "60                WEST ASIA  2018               407919.0   \n",
       "61                WEST ASIA  2019                88671.0   \n",
       "62                WEST ASIA  2020                88671.0   \n",
       "63                WEST ASIA  2021                47675.0   \n",
       "64                WEST ASIA  2022               239361.0   \n",
       "65           WESTERN EUROPE  2013              1851052.0   \n",
       "66           WESTERN EUROPE  2016              2016141.0   \n",
       "67           WESTERN EUROPE  2017              2159027.0   \n",
       "68           WESTERN EUROPE  2018              2228239.0   \n",
       "69           WESTERN EUROPE  2019              2159027.0   \n",
       "70           WESTERN EUROPE  2020               619678.0   \n",
       "71           WESTERN EUROPE  2021               333083.0   \n",
       "72           WESTERN EUROPE  2022              1289865.0   \n",
       "\n",
       "    BUSINESS AND PROFESSIONAL  LEISURE HOLIDAY AND RECREATION  MEDICAL  \\\n",
       "0                      130.18                          286.66   115.32   \n",
       "1                      133.00                          143.08   126.14   \n",
       "2                         NaN                             NaN      NaN   \n",
       "3                      133.00                          143.08   126.14   \n",
       "4                         NaN                             NaN      NaN   \n",
       "5                         NaN                             NaN      NaN   \n",
       "6                      165.30                          170.80   121.90   \n",
       "7                       18.85                           98.58     0.11   \n",
       "8                       10.50                           88.30     0.30   \n",
       "9                         NaN                             NaN      NaN   \n",
       "10                      10.50                           88.30     0.30   \n",
       "11                        NaN                             NaN      NaN   \n",
       "12                        NaN                             NaN      NaN   \n",
       "13                       7.00                           54.60     0.30   \n",
       "14                      53.10                          222.20     0.40   \n",
       "15                      48.27                          236.44     0.10   \n",
       "16                      62.08                          208.79     0.20   \n",
       "17                        NaN                             NaN      NaN   \n",
       "18                      62.08                          208.79     0.20   \n",
       "19                        NaN                             NaN      NaN   \n",
       "20                        NaN                             NaN      NaN   \n",
       "21                      81.80                          176.10     0.50   \n",
       "22                     184.67                          194.70     0.02   \n",
       "23                     172.50                          210.20     0.00   \n",
       "24                        NaN                             NaN      NaN   \n",
       "25                     172.50                          210.20     0.00   \n",
       "26                        NaN                             NaN      NaN   \n",
       "27                        NaN                             NaN      NaN   \n",
       "28                     174.70                           41.60     0.20   \n",
       "29                     118.53                          446.61     2.28   \n",
       "30                     109.04                          407.69     3.12   \n",
       "31                        NaN                             NaN      NaN   \n",
       "32                     109.04                          407.69     3.12   \n",
       "33                        NaN                             NaN      NaN   \n",
       "34                        NaN                             NaN      NaN   \n",
       "35                     148.40                          340.80     7.10   \n",
       "36                      17.50                           92.60     0.20   \n",
       "37                      16.44                          110.62     0.14   \n",
       "38                      16.06                           89.50     0.22   \n",
       "39                        NaN                             NaN      NaN   \n",
       "40                      16.06                           89.50     0.22   \n",
       "41                        NaN                             NaN      NaN   \n",
       "42                        NaN                             NaN      NaN   \n",
       "43                       6.40                           47.40     0.40   \n",
       "44                      58.30                          438.16   136.08   \n",
       "45                      68.80                          429.80   132.80   \n",
       "46                        NaN                             NaN      NaN   \n",
       "47                      68.80                          429.80   132.80   \n",
       "48                        NaN                             NaN      NaN   \n",
       "49                        NaN                             NaN      NaN   \n",
       "50                      65.30                          210.60    44.70   \n",
       "51                     116.02                          460.40     4.12   \n",
       "52                      91.00                          478.70     6.30   \n",
       "53                        NaN                             NaN      NaN   \n",
       "54                      91.00                          478.70     6.30   \n",
       "55                        NaN                             NaN      NaN   \n",
       "56                        NaN                             NaN      NaN   \n",
       "57                      83.70                          344.80    23.00   \n",
       "58                      94.55                          506.18   134.29   \n",
       "59                      94.60                          421.60   211.60   \n",
       "60                        NaN                             NaN      NaN   \n",
       "61                      94.60                          421.60   211.60   \n",
       "62                        NaN                             NaN      NaN   \n",
       "63                        NaN                             NaN      NaN   \n",
       "64                      85.90                          321.50   193.20   \n",
       "65                     386.20                          893.10     0.90   \n",
       "66                     394.31                          925.19     1.20   \n",
       "67                     355.45                          761.72     1.86   \n",
       "68                        NaN                             NaN      NaN   \n",
       "69                     355.45                          761.72     1.86   \n",
       "70                        NaN                             NaN      NaN   \n",
       "71                        NaN                             NaN      NaN   \n",
       "72                     329.30                          524.90     5.40   \n",
       "\n",
       "    INDIAN DIASPORA  OTHERS  \n",
       "0            101.18   66.74  \n",
       "1             45.90  151.90  \n",
       "2               NaN     NaN  \n",
       "3             45.90  151.90  \n",
       "4               NaN     NaN  \n",
       "5               NaN     NaN  \n",
       "6             65.00  177.00  \n",
       "7             75.32    7.15  \n",
       "8             70.10   30.70  \n",
       "9               NaN     NaN  \n",
       "10            70.10   30.70  \n",
       "11              NaN     NaN  \n",
       "12              NaN     NaN  \n",
       "13            84.10   54.00  \n",
       "14             2.10   22.20  \n",
       "15            11.12    4.07  \n",
       "16             4.72   24.20  \n",
       "17              NaN     NaN  \n",
       "18             4.72   24.20  \n",
       "19              NaN     NaN  \n",
       "20              NaN     NaN  \n",
       "21             8.80   32.80  \n",
       "22            14.90    5.72  \n",
       "23            10.20    7.00  \n",
       "24              NaN     NaN  \n",
       "25            10.20    7.00  \n",
       "26              NaN     NaN  \n",
       "27              NaN     NaN  \n",
       "28            30.00   53.50  \n",
       "29            18.69   13.89  \n",
       "30            14.70   65.45  \n",
       "31              NaN     NaN  \n",
       "32            14.70   65.45  \n",
       "33              NaN     NaN  \n",
       "34              NaN     NaN  \n",
       "35            26.10   77.60  \n",
       "36            76.80   12.90  \n",
       "37            65.49    7.31  \n",
       "38            50.97   43.25  \n",
       "39              NaN     NaN  \n",
       "40            50.97   43.25  \n",
       "41              NaN     NaN  \n",
       "42              NaN     NaN  \n",
       "43            89.60   56.20  \n",
       "44            54.09  113.37  \n",
       "45            39.30  129.70  \n",
       "46              NaN     NaN  \n",
       "47            39.30  129.70  \n",
       "48              NaN     NaN  \n",
       "49              NaN     NaN  \n",
       "50            18.20  461.20  \n",
       "51            72.73   46.74  \n",
       "52            43.70   80.10  \n",
       "53              NaN     NaN  \n",
       "54            43.70   80.10  \n",
       "55              NaN     NaN  \n",
       "56              NaN     NaN  \n",
       "57            44.60  203.90  \n",
       "58            28.78   36.22  \n",
       "59            33.20   38.90  \n",
       "60              NaN     NaN  \n",
       "61            33.20   38.90  \n",
       "62              NaN     NaN  \n",
       "63              NaN     NaN  \n",
       "64            26.50  172.90  \n",
       "65           199.90  119.90  \n",
       "66           235.69   43.59  \n",
       "67           229.37  251.54  \n",
       "68              NaN     NaN  \n",
       "69           229.37  251.54  \n",
       "70              NaN     NaN  \n",
       "71              NaN     NaN  \n",
       "72           343.60  397.10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def remove_columns_for_years(df, years_to_remove=[2018, 2020, 2021], columns_to_remove=None):\n",
    "    # Set default columns to remove if not provided\n",
    "    if columns_to_remove is None:\n",
    "        columns_to_remove = ['BUSINESS AND PROFESSIONAL', 'LEISURE HOLIDAY AND RECREATION', \n",
    "                             'MEDICAL', 'INDIAN DIASPORA', 'OTHERS']\n",
    "    \n",
    "    # Replace the specified columns with NaN for the specified years\n",
    "    df.loc[df['YEAR'].isin(years_to_remove), columns_to_remove] = np.nan\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "continent_yearly_removed_df = remove_columns_for_years(continent_yearly_df.copy())\n",
    "continent_yearly_removed_df\n",
    "# continent_yearly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_imputation(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df.groupby('CONTINENT')[column].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fill_imputation(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df.groupby('CONTINENT')[column].ffill()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def knn_imputation(df, columns, n_neighbors=3):\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Impute only the specified columns\n",
    "    df[columns] = imputer.fit_transform(df[columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seasonal Decomposition with interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def seasonal_interpolation(df, columns, frequency=1):\n",
    "    for column in columns:\n",
    "        # Temporarily interpolate missing values for decomposition\n",
    "        temp_series = df[column].interpolate(method='linear')\n",
    "        \n",
    "        # Decompose the interpolated series\n",
    "        decomposed = seasonal_decompose(temp_series, model='additive', period=frequency)\n",
    "        \n",
    "        # Replace NaNs in the original data with the trend + seasonal + residual from decomposed result\n",
    "        df[column].fillna(decomposed.trend + decomposed.seasonal + decomposed.resid, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].interpolate(method='linear')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time-Series Imputation with Rolling Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_mean_imputation(df, columns, window=2):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].fillna(df[column].rolling(window=window, min_periods=1).mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to be imputed\n",
    "columns_to_impute = ['BUSINESS AND PROFESSIONAL', 'LEISURE HOLIDAY AND RECREATION', \n",
    "                     'MEDICAL', 'INDIAN DIASPORA', 'OTHERS']\n",
    "\n",
    "# Make copies of the DataFrame for each imputation method\n",
    "df_mean_imputed = mean_imputation(continent_yearly_removed_df.copy(), columns_to_impute)\n",
    "df_ffill_imputed = forward_fill_imputation(continent_yearly_removed_df.copy(), columns_to_impute)\n",
    "df_knn_imputed = knn_imputation(continent_yearly_removed_df.copy(), columns_to_impute, n_neighbors=3)\n",
    "df_seasonal_imputed = seasonal_interpolation(continent_yearly_removed_df.copy(), columns_to_impute, frequency=1)\n",
    "df_linear_imputed = linear_interpolation(continent_yearly_removed_df.copy(), columns_to_impute)\n",
    "df_rolling_mean_imputed = rolling_mean_imputation(continent_yearly_removed_df.copy(), columns_to_impute, window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continent_yearly_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_knn_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_imputation_with_threshold(imputed_df, original_df, columns, threshold=5):\n",
    "    results = {}\n",
    "    accuracy_counts = {column: 0 for column in columns}  # Track correct imputations for each column\n",
    "    total_counts = {column: 0 for column in columns}  # Track total imputations for each column\n",
    "\n",
    "    for column in columns:\n",
    "        # Filter out rows where the original data has NaN (the rows we removed)\n",
    "        mask = original_df[column].notna()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(original_df.loc[mask, column], imputed_df.loc[mask, column])\n",
    "        mse = mean_squared_error(original_df.loc[mask, column], imputed_df.loc[mask, column])\n",
    "        r2 = r2_score(original_df.loc[mask, column], imputed_df.loc[mask, column])\n",
    "        \n",
    "        # Count correct imputations within the threshold\n",
    "        differences = (imputed_df.loc[mask, column] - original_df.loc[mask, column]).abs()\n",
    "        correct_count = (differences <= threshold).sum()  # Count values within 5 difference\n",
    "        total_count = len(differences)  # Total number of imputations for the column\n",
    "        \n",
    "        # Calculate percentage accuracy\n",
    "        accuracy = correct_count / total_count * 100 if total_count > 0 else None\n",
    "\n",
    "        # Store results\n",
    "        results[column] = {\n",
    "            'Mean Absolute Error': mae,\n",
    "            'Mean Squared Error': mse,\n",
    "            'R-squared': r2,\n",
    "            'Accuracy within 5': accuracy\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# List of columns with missing data that were imputed\n",
    "columns_to_evaluate = ['BUSINESS AND PROFESSIONAL', 'LEISURE HOLIDAY AND RECREATION', \n",
    "                       'MEDICAL', 'INDIAN DIASPORA', 'OTHERS']\n",
    "\n",
    "# Evaluate each imputed DataFrame\n",
    "mean_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_mean_imputed, continent_yearly_df, columns_to_evaluate)\n",
    "ffill_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_ffill_imputed, continent_yearly_df, columns_to_evaluate)\n",
    "knn_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_knn_imputed, continent_yearly_df, columns_to_evaluate)\n",
    "seasonal_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_seasonal_imputed, continent_yearly_df, columns_to_evaluate)\n",
    "linear_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_linear_imputed, continent_yearly_df, columns_to_evaluate)\n",
    "rolling_mean_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_rolling_mean_imputed, continent_yearly_df, columns_to_evaluate)\n",
    "\n",
    "# Display results\n",
    "# print(\"Mean Imputation Scores:\\n\", mean_imputed_scores)\n",
    "# print(\"\\nForward Fill Imputation Scores:\\n\", ffill_imputed_scores)\n",
    "# print(\"\\nKNN Imputation Scores:\\n\", knn_imputed_scores)\n",
    "\n",
    "\n",
    "mean_imputed_scores_with_threshold=pd.DataFrame(mean_imputed_scores_with_threshold)\n",
    "ffill_imputed_scores_with_threshold=pd.DataFrame(ffill_imputed_scores_with_threshold)\n",
    "knn_imputed_scores_with_threshold=pd.DataFrame(knn_imputed_scores_with_threshold)\n",
    "seasonal_imputed_scores_with_threshold=pd.DataFrame(seasonal_imputed_scores_with_threshold)\n",
    "linear_imputed_scores_with_threshold=pd.DataFrame(linear_imputed_scores_with_threshold)\n",
    "rolling_mean_imputed_scores_with_threshold=pd.DataFrame(rolling_mean_imputed_scores_with_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 -> Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>13.182342</td>\n",
       "      <td>48.601418</td>\n",
       "      <td>7.721000</td>\n",
       "      <td>15.279363</td>\n",
       "      <td>20.316829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1117.729124</td>\n",
       "      <td>13971.400689</td>\n",
       "      <td>664.001870</td>\n",
       "      <td>3754.122698</td>\n",
       "      <td>2088.364056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.896955</td>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.889366</td>\n",
       "      <td>0.651746</td>\n",
       "      <td>0.768398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>69.863014</td>\n",
       "      <td>60.273973</td>\n",
       "      <td>83.561644</td>\n",
       "      <td>69.863014</td>\n",
       "      <td>63.013699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BUSINESS AND PROFESSIONAL  \\\n",
       "Mean Absolute Error                  13.182342   \n",
       "Mean Squared Error                 1117.729124   \n",
       "R-squared                             0.896955   \n",
       "Accuracy within 5                   69.863014   \n",
       "\n",
       "                     LEISURE HOLIDAY AND RECREATION     MEDICAL  \\\n",
       "Mean Absolute Error                       48.601418    7.721000   \n",
       "Mean Squared Error                     13971.400689  664.001870   \n",
       "R-squared                                  0.734762    0.889366   \n",
       "Accuracy within 5                        60.273973   83.561644   \n",
       "\n",
       "                     INDIAN DIASPORA       OTHERS  \n",
       "Mean Absolute Error        15.279363    20.316829  \n",
       "Mean Squared Error       3754.122698  2088.364056  \n",
       "R-squared                   0.651746     0.768398  \n",
       "Accuracy within 5         69.863014    63.013699  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>13.377397</td>\n",
       "      <td>47.659178</td>\n",
       "      <td>6.912329</td>\n",
       "      <td>16.476986</td>\n",
       "      <td>19.295068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1191.826415</td>\n",
       "      <td>14753.578178</td>\n",
       "      <td>529.706795</td>\n",
       "      <td>4120.464200</td>\n",
       "      <td>2227.839888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.890123</td>\n",
       "      <td>0.719913</td>\n",
       "      <td>0.911742</td>\n",
       "      <td>0.617762</td>\n",
       "      <td>0.752930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>71.232877</td>\n",
       "      <td>65.753425</td>\n",
       "      <td>84.931507</td>\n",
       "      <td>75.342466</td>\n",
       "      <td>68.493151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BUSINESS AND PROFESSIONAL  \\\n",
       "Mean Absolute Error                  13.377397   \n",
       "Mean Squared Error                 1191.826415   \n",
       "R-squared                             0.890123   \n",
       "Accuracy within 5                   71.232877   \n",
       "\n",
       "                     LEISURE HOLIDAY AND RECREATION     MEDICAL  \\\n",
       "Mean Absolute Error                       47.659178    6.912329   \n",
       "Mean Squared Error                     14753.578178  529.706795   \n",
       "R-squared                                  0.719913    0.911742   \n",
       "Accuracy within 5                        65.753425   84.931507   \n",
       "\n",
       "                     INDIAN DIASPORA       OTHERS  \n",
       "Mean Absolute Error        16.476986    19.295068  \n",
       "Mean Squared Error       4120.464200  2227.839888  \n",
       "R-squared                   0.617762     0.752930  \n",
       "Accuracy within 5         75.342466    68.493151  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffill_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>33.922733</td>\n",
       "      <td>85.864511</td>\n",
       "      <td>28.108092</td>\n",
       "      <td>25.658662</td>\n",
       "      <td>29.513132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>4685.731714</td>\n",
       "      <td>24368.086172</td>\n",
       "      <td>3468.916321</td>\n",
       "      <td>7798.334859</td>\n",
       "      <td>3263.103153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.568014</td>\n",
       "      <td>0.537388</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.276581</td>\n",
       "      <td>0.638118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>58.904110</td>\n",
       "      <td>58.904110</td>\n",
       "      <td>58.904110</td>\n",
       "      <td>61.643836</td>\n",
       "      <td>58.904110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BUSINESS AND PROFESSIONAL  \\\n",
       "Mean Absolute Error                  33.922733   \n",
       "Mean Squared Error                 4685.731714   \n",
       "R-squared                             0.568014   \n",
       "Accuracy within 5                   58.904110   \n",
       "\n",
       "                     LEISURE HOLIDAY AND RECREATION      MEDICAL  \\\n",
       "Mean Absolute Error                       85.864511    28.108092   \n",
       "Mean Squared Error                     24368.086172  3468.916321   \n",
       "R-squared                                  0.537388     0.422018   \n",
       "Accuracy within 5                        58.904110    58.904110   \n",
       "\n",
       "                     INDIAN DIASPORA       OTHERS  \n",
       "Mean Absolute Error        25.658662    29.513132  \n",
       "Mean Squared Error       7798.334859  3263.103153  \n",
       "R-squared                   0.276581     0.638118  \n",
       "Accuracy within 5         61.643836    58.904110  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>12.928767</td>\n",
       "      <td>43.064292</td>\n",
       "      <td>8.310137</td>\n",
       "      <td>14.878904</td>\n",
       "      <td>20.051416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1054.305272</td>\n",
       "      <td>9489.891154</td>\n",
       "      <td>792.095032</td>\n",
       "      <td>3039.702793</td>\n",
       "      <td>2133.950506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.902802</td>\n",
       "      <td>0.819841</td>\n",
       "      <td>0.868023</td>\n",
       "      <td>0.718020</td>\n",
       "      <td>0.763343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>72.602740</td>\n",
       "      <td>58.904110</td>\n",
       "      <td>80.821918</td>\n",
       "      <td>72.602740</td>\n",
       "      <td>65.753425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BUSINESS AND PROFESSIONAL  \\\n",
       "Mean Absolute Error                  12.928767   \n",
       "Mean Squared Error                 1054.305272   \n",
       "R-squared                             0.902802   \n",
       "Accuracy within 5                   72.602740   \n",
       "\n",
       "                     LEISURE HOLIDAY AND RECREATION     MEDICAL  \\\n",
       "Mean Absolute Error                       43.064292    8.310137   \n",
       "Mean Squared Error                      9489.891154  792.095032   \n",
       "R-squared                                  0.819841    0.868023   \n",
       "Accuracy within 5                        58.904110   80.821918   \n",
       "\n",
       "                     INDIAN DIASPORA       OTHERS  \n",
       "Mean Absolute Error        14.878904    20.051416  \n",
       "Mean Squared Error       3039.702793  2133.950506  \n",
       "R-squared                   0.718020     0.763343  \n",
       "Accuracy within 5         72.602740    65.753425  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonal_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>12.928767</td>\n",
       "      <td>43.064292</td>\n",
       "      <td>8.310137</td>\n",
       "      <td>14.878904</td>\n",
       "      <td>20.051416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1054.305272</td>\n",
       "      <td>9489.891154</td>\n",
       "      <td>792.095032</td>\n",
       "      <td>3039.702793</td>\n",
       "      <td>2133.950506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.902802</td>\n",
       "      <td>0.819841</td>\n",
       "      <td>0.868023</td>\n",
       "      <td>0.718020</td>\n",
       "      <td>0.763343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>72.602740</td>\n",
       "      <td>58.904110</td>\n",
       "      <td>80.821918</td>\n",
       "      <td>72.602740</td>\n",
       "      <td>65.753425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BUSINESS AND PROFESSIONAL  \\\n",
       "Mean Absolute Error                  12.928767   \n",
       "Mean Squared Error                 1054.305272   \n",
       "R-squared                             0.902802   \n",
       "Accuracy within 5                   72.602740   \n",
       "\n",
       "                     LEISURE HOLIDAY AND RECREATION     MEDICAL  \\\n",
       "Mean Absolute Error                       43.064292    8.310137   \n",
       "Mean Squared Error                      9489.891154  792.095032   \n",
       "R-squared                                  0.819841    0.868023   \n",
       "Accuracy within 5                        58.904110   80.821918   \n",
       "\n",
       "                     INDIAN DIASPORA       OTHERS  \n",
       "Mean Absolute Error        14.878904    20.051416  \n",
       "Mean Squared Error       3039.702793  2133.950506  \n",
       "R-squared                   0.718020     0.763343  \n",
       "Accuracy within 5         72.602740    65.753425  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSINESS AND PROFESSIONAL</th>\n",
       "      <th>LEISURE HOLIDAY AND RECREATION</th>\n",
       "      <th>MEDICAL</th>\n",
       "      <th>INDIAN DIASPORA</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>12.809795</td>\n",
       "      <td>44.955068</td>\n",
       "      <td>6.975890</td>\n",
       "      <td>15.742260</td>\n",
       "      <td>16.021507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1172.879673</td>\n",
       "      <td>14225.233388</td>\n",
       "      <td>534.958090</td>\n",
       "      <td>4092.042852</td>\n",
       "      <td>1515.149449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.891870</td>\n",
       "      <td>0.729943</td>\n",
       "      <td>0.910867</td>\n",
       "      <td>0.620398</td>\n",
       "      <td>0.831968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>72.602740</td>\n",
       "      <td>65.753425</td>\n",
       "      <td>84.931507</td>\n",
       "      <td>75.342466</td>\n",
       "      <td>68.493151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BUSINESS AND PROFESSIONAL  \\\n",
       "Mean Absolute Error                  12.809795   \n",
       "Mean Squared Error                 1172.879673   \n",
       "R-squared                             0.891870   \n",
       "Accuracy within 5                   72.602740   \n",
       "\n",
       "                     LEISURE HOLIDAY AND RECREATION     MEDICAL  \\\n",
       "Mean Absolute Error                       44.955068    6.975890   \n",
       "Mean Squared Error                     14225.233388  534.958090   \n",
       "R-squared                                  0.729943    0.910867   \n",
       "Accuracy within 5                        65.753425   84.931507   \n",
       "\n",
       "                     INDIAN DIASPORA       OTHERS  \n",
       "Mean Absolute Error        15.742260    16.021507  \n",
       "Mean Squared Error       4092.042852  1515.149449  \n",
       "R-squared                   0.620398     0.831968  \n",
       "Accuracy within 5         75.342466    68.493151  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_mean_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputed_scores_with_threshold.to_csv(\"1_mean_imputed_scores_with_threshold.csv\")\n",
    "ffill_imputed_scores_with_threshold.to_csv(\"1_ffill_imputed_scores_with_threshold.csv\")\n",
    "knn_imputed_scores_with_threshold.to_csv(\"1_knn_imputed_scores_with_threshold.csv\")\n",
    "seasonal_imputed_scores_with_threshold.to_csv(\"1_seasonal_imputed_scores_with_threshold.csv\")\n",
    "linear_imputed_scores_with_threshold.to_csv(\"1_linear_imputed_scores_with_threshold.csv\")\n",
    "rolling_mean_imputed_scores_with_threshold.to_csv(\"1_rolling_mean_imputed_scores_with_threshold.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 -> Total No of Incoming tourists per continent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 -> Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2016</td>\n",
       "      <td>210646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2017</td>\n",
       "      <td>146639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2018</td>\n",
       "      <td>240262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2019</td>\n",
       "      <td>146639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2020</td>\n",
       "      <td>61070.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CONTINENT  YEAR  ARRIVALS (IN NUMBERS)\n",
       "0    AFRICA  2016               210646.0\n",
       "1    AFRICA  2017               146639.0\n",
       "2    AFRICA  2018               240262.0\n",
       "3    AFRICA  2019               146639.0\n",
       "4    AFRICA  2020                61070.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continent_arrival_df=continent_yearly_df[['CONTINENT','YEAR','ARRIVALS (IN NUMBERS)']]\n",
    "continent_arrival_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2016</td>\n",
       "      <td>210646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2017</td>\n",
       "      <td>146639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2019</td>\n",
       "      <td>146639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2022</td>\n",
       "      <td>149541.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CONTINENT  YEAR  ARRIVALS (IN NUMBERS)\n",
       "0    AFRICA  2016               210646.0\n",
       "1    AFRICA  2017               146639.0\n",
       "2    AFRICA  2018                    NaN\n",
       "3    AFRICA  2019               146639.0\n",
       "4    AFRICA  2020                    NaN\n",
       "5    AFRICA  2021                    NaN\n",
       "6    AFRICA  2022               149541.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_columns_for_years(df, years_to_remove=[2018, 2020, 2021], columns_to_remove=None):\n",
    "    # Set default columns to remove if not provided\n",
    "    if columns_to_remove is None:\n",
    "        columns_to_remove = ['ARRIVALS (IN NUMBERS)']\n",
    "    \n",
    "    # Replace the specified columns with NaN for the specified years\n",
    "    df.loc[df['YEAR'].isin(years_to_remove), columns_to_remove] = np.nan\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "continent_arrival_removed_df = remove_columns_for_years(continent_arrival_df.copy())\n",
    "continent_arrival_removed_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to be imputed\n",
    "columns_to_impute = ['ARRIVALS (IN NUMBERS)']\n",
    "\n",
    "# Make copies of the DataFrame for each imputation method\n",
    "df_mean_imputed = mean_imputation(continent_arrival_removed_df.copy(), columns_to_impute)\n",
    "df_ffill_imputed = forward_fill_imputation(continent_arrival_removed_df.copy(), columns_to_impute)\n",
    "df_knn_imputed = knn_imputation(continent_arrival_removed_df.copy(), columns_to_impute, n_neighbors=3)\n",
    "df_seasonal_imputed = seasonal_interpolation(continent_arrival_removed_df.copy(), columns_to_impute, frequency=1)\n",
    "df_linear_imputed = linear_interpolation(continent_arrival_removed_df.copy(), columns_to_impute)\n",
    "df_rolling_mean_imputed = rolling_mean_imputation(continent_arrival_removed_df.copy(), columns_to_impute, window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_evaluate = ['ARRIVALS (IN NUMBERS)']\n",
    "\n",
    "# Evaluate each imputed DataFrame\n",
    "mean_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_mean_imputed, continent_arrival_df, columns_to_evaluate)\n",
    "ffill_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_ffill_imputed, continent_arrival_df, columns_to_evaluate)\n",
    "knn_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_knn_imputed, continent_arrival_df, columns_to_evaluate)\n",
    "seasonal_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_seasonal_imputed, continent_arrival_df, columns_to_evaluate)\n",
    "linear_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_linear_imputed, continent_arrival_df, columns_to_evaluate)\n",
    "rolling_mean_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_rolling_mean_imputed, continent_arrival_df, columns_to_evaluate)\n",
    "\n",
    "# Display results\n",
    "# print(\"Mean Imputation Scores:\\n\", mean_imputed_scores)\n",
    "# print(\"\\nForward Fill Imputation Scores:\\n\", ffill_imputed_scores)\n",
    "# print(\"\\nKNN Imputation Scores:\\n\", knn_imputed_scores)\n",
    "\n",
    "\n",
    "mean_imputed_scores_with_threshold=pd.DataFrame(mean_imputed_scores_with_threshold)\n",
    "ffill_imputed_scores_with_threshold=pd.DataFrame(ffill_imputed_scores_with_threshold)\n",
    "knn_imputed_scores_with_threshold=pd.DataFrame(knn_imputed_scores_with_threshold)\n",
    "seasonal_imputed_scores_with_threshold=pd.DataFrame(seasonal_imputed_scores_with_threshold)\n",
    "linear_imputed_scores_with_threshold=pd.DataFrame(linear_imputed_scores_with_threshold)\n",
    "rolling_mean_imputed_scores_with_threshold=pd.DataFrame(rolling_mean_imputed_scores_with_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 -> Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.729507e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.677305e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>6.853721e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>5.890411e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ARRIVALS (IN NUMBERS)\n",
       "Mean Absolute Error           1.729507e+05\n",
       "Mean Squared Error            1.677305e+11\n",
       "R-squared                     6.853721e-01\n",
       "Accuracy within 5            5.890411e+01"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.654873e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>2.222108e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>5.831782e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>6.575342e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ARRIVALS (IN NUMBERS)\n",
       "Mean Absolute Error           1.654873e+05\n",
       "Mean Squared Error            2.222108e+11\n",
       "R-squared                     5.831782e-01\n",
       "Accuracy within 5            6.575342e+01"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffill_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>2.343139e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>2.202262e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>5.869010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>5.890411e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ARRIVALS (IN NUMBERS)\n",
       "Mean Absolute Error           2.343139e+05\n",
       "Mean Squared Error            2.202262e+11\n",
       "R-squared                     5.869010e-01\n",
       "Accuracy within 5            5.890411e+01"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.702946e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.951013e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>6.340300e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>5.890411e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ARRIVALS (IN NUMBERS)\n",
       "Mean Absolute Error           1.702946e+05\n",
       "Mean Squared Error            1.951013e+11\n",
       "R-squared                     6.340300e-01\n",
       "Accuracy within 5            5.890411e+01"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonal_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.702946e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.951013e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>6.340300e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>5.890411e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ARRIVALS (IN NUMBERS)\n",
       "Mean Absolute Error           1.702946e+05\n",
       "Mean Squared Error            1.951013e+11\n",
       "R-squared                     6.340300e-01\n",
       "Accuracy within 5            5.890411e+01"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARRIVALS (IN NUMBERS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.459679e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.743241e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>6.730039e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>6.575342e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ARRIVALS (IN NUMBERS)\n",
       "Mean Absolute Error           1.459679e+05\n",
       "Mean Squared Error            1.743241e+11\n",
       "R-squared                     6.730039e-01\n",
       "Accuracy within 5            6.575342e+01"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_mean_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputed_scores_with_threshold.to_csv(\"2_mean_imputed_scores_with_threshold.csv\")\n",
    "ffill_imputed_scores_with_threshold.to_csv(\"2_ffill_imputed_scores_with_threshold.csv\")\n",
    "knn_imputed_scores_with_threshold.to_csv(\"2_knn_imputed_scores_with_threshold.csv\")\n",
    "seasonal_imputed_scores_with_threshold.to_csv(\"2_seasonal_imputed_scores_with_threshold.csv\")\n",
    "linear_imputed_scores_with_threshold.to_csv(\"2_linear_imputed_scores_with_threshold.csv\")\n",
    "rolling_mean_imputed_scores_with_threshold.to_csv(\"2_rolling_mean_imputed_scores_with_threshold.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 -> No of domestic tourists per state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 -> Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_2013=pd.read_excel('../data-students/TourismData-2013/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2014=pd.read_excel('../data-students/TourismData-2014/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2016=pd.read_excel('../data-students/TourismData-2016/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2017=pd.read_excel('../data-students/TourismData-2017/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2018=pd.read_excel('../data-students/TourismData-2018/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2019=pd.read_excel('../data-students/TourismData-2019/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2020=pd.read_excel('../data-students/TourismData-2020/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2021=pd.read_excel('../data-students/TourismData-2021/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')\n",
    "df_state_2022=pd.read_excel('../data-students/TourismData-2022/STATE UT-WISE DOMESTIC AND FOREIGN TOURIST VISITS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State/UT', 'Domestic', 'Foreign'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state_2013.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_state=[df_state_2013,df_state_2014,df_state_2016,df_state_2017,df_state_2018,df_state_2019,df_state_2020,df_state_2021,df_state_2022]\n",
    "for df in list_state:\n",
    "    # df = df.drop(columns=[\"Foreign\"])\n",
    "    df.columns = df.columns.str.upper()\n",
    "    df['STATE/UT'] = df['STATE/UT'].str.upper()\n",
    "    df['STATE/UT'] = df['STATE/UT'].str.strip()\n",
    "\n",
    "# list_state=[df_state_2013,df_state_2014,df_state_2016,df_state_2017,df_state_2018,df_state_2019,df_state_2020,df_state_2021,df_state_2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=[2013,2014,2016,2017,2018,2019,2020,2021,2022]\n",
    "# df=pd.DataFrame(columns=['COUNTRY OF NATIONALITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty list to store the updated DataFrames\n",
    "# df_combined = []\n",
    "\n",
    "# # Iterate through each DataFrame in the list\n",
    "# for df, year in zip(list_state, years):\n",
    "#     df = df.drop(columns=[\"FOREIGN\"])\n",
    "\n",
    "#     # Add a column 'Year' to each DataFrame\n",
    "#     df['Year'] = year\n",
    "#     # Append the DataFrame to the combined list\n",
    "#     df_combined.append(df)\n",
    "\n",
    "# # Concatenate all the DataFrames into one\n",
    "# df_result = pd.concat(df_combined, ignore_index=True)\n",
    "\n",
    "# # Now, df_result contains the combined data with the year column\n",
    "# # print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrames and years list\n",
    "# list_state = [df_state_2013, df_state_2014, df_state_2016, df_state_2017, df_state_2018, df_state_2019, df_state_2020, df_state_2021, df_state_2022]\n",
    "# years = [2013, 2014, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "# Create an empty list to store the updated DataFrames\n",
    "df_combined = []\n",
    "df_combined_removed = []\n",
    "\n",
    "# Iterate through each DataFrame and year, dropping \"FOREIGN\" column and adding \"Year\"\n",
    "for df, year in zip(list_state, years):\n",
    "    df = df.drop(columns=[\"FOREIGN\"])\n",
    "    df['Year'] = year\n",
    "    \n",
    "    df_combined.append(df.copy())\n",
    "\n",
    "    # Set 'DOMESTIC' values to NaN for specified years\n",
    "    if year in [2018, 2020, 2021]:\n",
    "        df['DOMESTIC'] = np.nan\n",
    "\n",
    "    df_combined_removed.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_result = pd.concat(df_combined, ignore_index=True)\n",
    "df_result_removed = pd.concat(df_combined_removed, ignore_index=True)\n",
    "\n",
    "# Sort by 'STATE/UT' to group similar entries together\n",
    "df_result = df_result.sort_values(by=\"STATE/UT\").reset_index(drop=True)\n",
    "df_result_removed =df_result_removed.sort_values(by=\"STATE/UT\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display the result\n",
    "# print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>498279.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>191207.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>126238.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS  498279.0  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS  191207.0  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS  126238.0  2021"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS       NaN  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS       NaN  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS       NaN  2021"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty list to store the modified DataFrames\n",
    "# df_combined = []\n",
    "\n",
    "# # Iterate through each DataFrame in the list\n",
    "# for df, year in zip(list_state, years):\n",
    "#     # Drop the \"FOREIGN\" column\n",
    "#     df = df.drop(columns=[\"FOREIGN\"])\n",
    "#     # Rename the \"DOMESTIC\" column to reflect the year\n",
    "#     df.rename(columns={\"DOMESTIC\": f\"Domestic_{year}\"}, inplace=True)\n",
    "#     # Append the modified DataFrame to the combined list\n",
    "#     df_combined.append(df)\n",
    "\n",
    "# # Merge all DataFrames on the \"STATE/UT\" column\n",
    "# df_result = pd.concat(df_combined, axis=1)\n",
    "\n",
    "# # Drop duplicate \"STATE/UT\" columns (will keep only the first one)\n",
    "# df_result = df_result.loc[:, ~df_result.columns.duplicated()]\n",
    "\n",
    "# df_result = df_result.dropna()\n",
    "\n",
    "# df_result_removed=df_result.copy()\n",
    "\n",
    "# df_result_removed[\"Domestic_2018\"] = np.nan\n",
    "# df_result_removed[\"Domestic_2020\"] = np.nan\n",
    "# df_result_removed[\"Domestic_2021\"] = np.nan\n",
    "\n",
    "# # Now, df_result contains the desired structure\n",
    "# # print(df_result)\n",
    "# df_result_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>498279.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>191207.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>126238.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS  498279.0  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS  191207.0  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS  126238.0  2021"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result_removed.to_csv(\"temp1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_imputation(df):\n",
    "#     return df.fillna(df.mean())\n",
    "\n",
    "def mean_imputation(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df.groupby('STATE/UT')[column].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forward Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_fill(df):\n",
    "#     return df.fillna(method='ffill')\n",
    "\n",
    "def forward_fill_imputation(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df.groupby('STATE/UT')[column].ffill()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def knn_imputation(df, n_neighbors=5):\n",
    "#     imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "#     df_imputed = imputer.fit_transform(df)\n",
    "#     return pd.DataFrame(df_imputed, columns=df.columns)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def knn_imputation(df, columns, n_neighbors=3):\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Impute only the specified columns\n",
    "    df[columns] = imputer.fit_transform(df[columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seasonal Decomposition with Interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# def seasonal_decomposition_imputation(df):\n",
    "#     # Assuming 'df' is a time-series data (indexed by time)\n",
    "#     df_imputed = df.copy()\n",
    "#     for column in df.columns:\n",
    "#         # Decompose each column\n",
    "#         decomposition = seasonal_decompose(df[column], model='additive', period=12)  # Assuming monthly data\n",
    "#         decomposed = decomposition.trend + decomposition.seasonal  # Reconstruct series\n",
    "#         df_imputed[column] = decomposed.interpolate()  # Interpolate missing values\n",
    "#     return df_imputed\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def seasonal_interpolation(df, columns, frequency=1):\n",
    "    for column in columns:\n",
    "        # Temporarily interpolate missing values for decomposition\n",
    "        temp_series = df[column].interpolate(method='linear')\n",
    "        \n",
    "        # Decompose the interpolated series\n",
    "        decomposed = seasonal_decompose(temp_series, model='additive', period=frequency)\n",
    "        \n",
    "        # Replace NaNs in the original data with the trend + seasonal + residual from decomposed result\n",
    "        df[column].fillna(decomposed.trend + decomposed.seasonal + decomposed.resid, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def linear_interpolation(df):\n",
    "#     return df.interpolate(method='linear', axis=0)\n",
    "\n",
    "def linear_interpolation(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].interpolate(method='linear')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time-Series Imputation with Rolling Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rolling_mean_imputation(df, window=3):\n",
    "#     return df.fillna(df.rolling(window=window, min_periods=1).mean())\n",
    "\n",
    "def rolling_mean_imputation(df, columns, window=2):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].fillna(df[column].rolling(window=window, min_periods=1).mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Columns to be imputed\n",
    "# columns_to_impute = ['Domestic_2018','Domestic_2020','Domestic_2021']\n",
    "\n",
    "# # Make copies of the DataFrame for each imputation method\n",
    "# df_mean_imputed = mean_imputation(df_result_removed.copy(), columns_to_impute)\n",
    "# df_ffill_imputed = forward_fill(df_result_removed.copy(), columns_to_impute)\n",
    "# df_knn_imputed = knn_imputation(df_result_removed.copy(), columns_to_impute, n_neighbors=3)\n",
    "# df_seasonal_imputed = seasonal_decomposition_imputation(df_result_removed.copy(), columns_to_impute,frequency=1)\n",
    "# df_linear_imputed = linear_interpolation(df_result_removed.copy(), columns_to_impute)\n",
    "# df_rolling_mean_imputed = rolling_mean_imputation(df_result_removed.copy(), columns_to_impute, window=3)\n",
    "\n",
    "# Columns to be imputed\n",
    "# columns_to_impute = ['Domestic_2018','Domestic_2020','Domestic_2021']\n",
    "# df_result_removed.set_index('STATE/UT', inplace=True)\n",
    "# Make copies of the DataFrame for each imputation method\n",
    "# df_mean_imputed = mean_imputation(df_result_removed.copy())\n",
    "# # df_mean_imputed = mean_imputation(df_result_removed.copy(), columns_to_impute)\n",
    "# df_ffill_imputed = forward_fill(df_result_removed.copy())\n",
    "# df_knn_imputed = knn_imputation(df_result_removed.copy(), n_neighbors=3)\n",
    "# df_seasonal_imputed = seasonal_decomposition_imputation(df_result_removed.copy())\n",
    "# df_linear_imputed = linear_interpolation(df_result_removed.copy() )\n",
    "# df_rolling_mean_imputed = rolling_mean_imputation(df_result_removed.copy(), window=3)\n",
    "\n",
    "\n",
    "# # 1. Forward Fill\n",
    "# result_df_ffill = df_result_removed.fillna(method='ffill')\n",
    "\n",
    "# # 2. Backward Fill\n",
    "# result_df_bfill = df_result_removed.fillna(method='bfill')\n",
    "\n",
    "# # 3. Linear Interpolation\n",
    "# result_df_interpolate_linear = df_result_removed.interpolate(method='linear')\n",
    "\n",
    "# # 4. Polynomial Interpolation (degree=2 for example)\n",
    "# result_df_interpolate_poly = df_result_removed.interpolate(method='polynomial', order=2)\n",
    "\n",
    "# # 5. Fill with a Specific Value (e.g., 0)\n",
    "# result_df_fill_zero = df_result_removed.fillna(0)\n",
    "\n",
    "# # 6. Fill with Mean or Median of each column\n",
    "# result_df_fill_mean = df_result_removed.apply(lambda col: col.fillna(col.mean()) if col.dtype in ['float64', 'int64'] else col)\n",
    "# result_df_fill_median = df_result_removed.apply(lambda col: col.fillna(col.median()) if col.dtype in ['float64', 'int64'] else col)\n",
    "\n",
    "# # Optionally, print or return the results to inspect the filled data\n",
    "# print(\"Forward Fill Result:\")\n",
    "# print(result_df_ffill.head())\n",
    "# print(\"\\nBackward Fill Result:\")\n",
    "# print(result_df_bfill.head())\n",
    "# print(\"\\nLinear Interpolation Result:\")\n",
    "# print(result_df_interpolate_linear.head())\n",
    "# print(\"\\nPolynomial Interpolation Result:\")\n",
    "# print(result_df_interpolate_poly.head())\n",
    "# print(\"\\nFill with Zero Result:\")\n",
    "# print(result_df_fill_zero.head())\n",
    "# print(\"\\nFill with Mean Result:\")\n",
    "# print(result_df_fill_mean.head())\n",
    "# print(\"\\nFill with Median Result:\")\n",
    "# print(result_df_fill_median.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS       NaN  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS       NaN  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS       NaN  2021"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>498279.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>191207.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>126238.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS  498279.0  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS  191207.0  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS  126238.0  2021"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute=['DOMESTIC']\n",
    "df_mean_imputed = mean_imputation(df_result_removed.copy(),columns_to_impute)\n",
    "# df_ffill_imputed = forward_fill(df_result_removed.copy())\n",
    "# df_knn_imputed = knn_imputation(df_result_removed.copy(), n_neighbors=3)\n",
    "# df_seasonal_imputed = seasonal_decomposition_imputation(df_result_removed.copy())\n",
    "# df_linear_imputed = linear_interpolation(df_result_removed.copy() )\n",
    "# df_rolling_mean_imputed = rolling_mean_imputation(df_result_removed.copy(), window=3)\n",
    "# df_mean_imputed = mean_imputation(df_result_removed.copy(), columns_to_impute)\n",
    "# df_ffill_imputed = forward_fill_imputation(df_result_removed.copy(),columns_to_impute)\n",
    "df_knn_imputed = knn_imputation(df_result_removed.copy(), columns_to_impute, n_neighbors=3)\n",
    "df_seasonal_imputed = seasonal_interpolation(df_result_removed.copy(), columns_to_impute, frequency=1)\n",
    "df_linear_imputed = linear_interpolation(df_result_removed.copy(), columns_to_impute)\n",
    "df_rolling_mean_imputed = rolling_mean_imputation(df_result_removed.copy(), columns_to_impute, window=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop column which could not be filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ffill_imputed=df_ffill_imputed.dropna()\n",
    "# df_ffill_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>498279.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>191207.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>126238.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS  498279.0  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS  191207.0  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS  126238.0  2021"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_imputation_with_threshold(imputed_df, original_df, columns, threshold=5):\n",
    "    results = {}\n",
    "    accuracy_counts = {column: 0 for column in columns}  # Track correct imputations for each column\n",
    "    total_counts = {column: 0 for column in columns}  # Track total imputations for each column\n",
    "\n",
    "    for column in columns:\n",
    "        # Filter out rows where the original data has NaN (the rows we removed)\n",
    "        mask = original_df[column].notna()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(original_df.loc[mask, column], imputed_df.loc[mask, column])\n",
    "        mse = mean_squared_error(original_df.loc[mask, column], imputed_df.loc[mask, column])\n",
    "        r2 = r2_score(original_df.loc[mask, column], imputed_df.loc[mask, column])\n",
    "        \n",
    "        # Count correct imputations within the threshold\n",
    "        differences = (imputed_df.loc[mask, column] - original_df.loc[mask, column]).abs()\n",
    "        correct_count = (differences <= threshold).sum()  # Count values within 5 difference\n",
    "        total_count = len(differences)  # Total number of imputations for the column\n",
    "        \n",
    "        # Calculate percentage accuracy\n",
    "        accuracy = correct_count / total_count * 100 if total_count > 0 else None\n",
    "\n",
    "        # Store results\n",
    "        results[column] = {\n",
    "            'Mean Absolute Error': mae,\n",
    "            'Mean Squared Error': mse,\n",
    "            'R-squared': r2,\n",
    "            'Accuracy within 5': accuracy\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# List of columns with missing data that were imputed\n",
    "# columns_to_evaluate = ['BUSINESS AND PROFESSIONAL', 'LEISURE HOLIDAY AND RECREATION', \n",
    "#                        'MEDICAL', 'INDIAN DIASPORA', 'OTHERS']\n",
    "\n",
    "columns_to_evaluate=['DOMESTIC']\n",
    "\n",
    "\n",
    "# Evaluate each imputed DataFrame\n",
    "mean_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_mean_imputed, df_result, columns_to_evaluate)\n",
    "mean_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_mean_imputed, df_result, columns_to_evaluate)\n",
    "# ffill_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_ffill_imputed, df_result, columns_to_evaluate)\n",
    "knn_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_knn_imputed, df_result, columns_to_evaluate)\n",
    "seasonal_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_seasonal_imputed, df_result, columns_to_evaluate)\n",
    "linear_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_linear_imputed, df_result, columns_to_evaluate)\n",
    "# rolling_mean_imputed_scores_with_threshold = evaluate_imputation_with_threshold(df_rolling_mean_imputed, df_result, columns_to_evaluate)\n",
    "\n",
    "# Display results\n",
    "# print(\"Mean Imputation Scores:\\n\", mean_imputed_scores)\n",
    "# print(\"\\nForward Fill Imputation Scores:\\n\", ffill_imputed_scores)\n",
    "# print(\"\\nKNN Imputation Scores:\\n\", knn_imputed_scores)\n",
    "\n",
    "\n",
    "mean_imputed_scores_with_threshold=pd.DataFrame(mean_imputed_scores_with_threshold)\n",
    "# ffill_imputed_scores_with_threshold=pd.DataFrame(ffill_imputed_scores_with_threshold)\n",
    "knn_imputed_scores_with_threshold=pd.DataFrame(knn_imputed_scores_with_threshold)\n",
    "seasonal_imputed_scores_with_threshold=pd.DataFrame(seasonal_imputed_scores_with_threshold)\n",
    "linear_imputed_scores_with_threshold=pd.DataFrame(linear_imputed_scores_with_threshold)\n",
    "# rolling_mean_imputed_scores_with_threshold=pd.DataFrame(rolling_mean_imputed_scores_with_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>498279.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>191207.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>126238.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS  498279.0  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS  191207.0  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS  126238.0  2021"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 -> Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE/UT</th>\n",
       "      <th>DOMESTIC</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>243703.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>471919.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDAMAN &amp; NICOBAR ISLANDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATE/UT  DOMESTIC  Year\n",
       "0  ANDAMAN & NICOBAR ISLANDS  243703.0  2013\n",
       "1  ANDAMAN & NICOBAR ISLANDS       NaN  2018\n",
       "2  ANDAMAN & NICOBAR ISLANDS       NaN  2020\n",
       "3  ANDAMAN & NICOBAR ISLANDS  471919.0  2017\n",
       "4  ANDAMAN & NICOBAR ISLANDS       NaN  2021"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_removed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMESTIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>7.077706e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>6.811933e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>8.799753e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>6.636086e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DOMESTIC\n",
       "Mean Absolute Error  7.077706e+06\n",
       "Mean Squared Error   6.811933e+14\n",
       "R-squared            8.799753e-01\n",
       "Accuracy within 5   6.636086e+01"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMESTIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.509942e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.221339e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>7.848029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>6.636086e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DOMESTIC\n",
       "Mean Absolute Error  1.509942e+07\n",
       "Mean Squared Error   1.221339e+15\n",
       "R-squared            7.848029e-01\n",
       "Accuracy within 5   6.636086e+01"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMESTIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.137806e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.258790e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>7.782040e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>6.636086e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DOMESTIC\n",
       "Mean Absolute Error  1.137806e+07\n",
       "Mean Squared Error   1.258790e+15\n",
       "R-squared            7.782040e-01\n",
       "Accuracy within 5   6.636086e+01"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonal_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOMESTIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>1.137806e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>1.258790e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>7.782040e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy within 5</th>\n",
       "      <td>6.636086e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DOMESTIC\n",
       "Mean Absolute Error  1.137806e+07\n",
       "Mean Squared Error   1.258790e+15\n",
       "R-squared            7.782040e-01\n",
       "Accuracy within 5   6.636086e+01"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling_mean_imputed_scores_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputed_scores_with_threshold.to_csv(\"3_mean_imputed_scores_with_threshold.csv\")\n",
    "# ffill_imputed_scores_with_threshold.to_csv(\"1_ffill_imputed_scores_with_threshold.csv\")\n",
    "knn_imputed_scores_with_threshold.to_csv(\"3_knn_imputed_scores_with_threshold.csv\")\n",
    "seasonal_imputed_scores_with_threshold.to_csv(\"3_seasonal_imputed_scores_with_threshold.csv\")\n",
    "linear_imputed_scores_with_threshold.to_csv(\"3_linear_imputed_scores_with_threshold.csv\")\n",
    "# rolling_mean_imputed_scores_with_threshold.to_csv(\"1_rolling_mean_imputed_scores_with_threshold.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Difference between imputation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = {\n",
    "    'Method': [\n",
    "        'Mean Imputation',\n",
    "        'Forward Fill',\n",
    "        'KNN Imputation',\n",
    "        'Seasonal Decomposition with Interpolation',\n",
    "        'Linear Interpolation',\n",
    "        'Time-Series Imputation with Rolling Mean'\n",
    "    ],\n",
    "    'Explanation': [\n",
    "        'Replaces missing values with the average of available data for each state.',\n",
    "        'Fills missing values by using the last known value for each state.',\n",
    "        'Estimates missing values based on K most similar data points across states.',\n",
    "        'Decomposes time series into trend, seasonal, and residual components, then interpolates.',\n",
    "        'Assumes a linear relationship between known data points to estimate missing values.',\n",
    "        'Uses a moving average of nearby time points to fill in missing values.'\n",
    "    ],\n",
    "    'Pros': [\n",
    "        'Simple, quick to implement. Works for randomly missing data.',\n",
    "        'Preserves trends. Simple to understand and implement.',\n",
    "        'Captures complex patterns and multivariate relationships.',\n",
    "        'Effective for data with clear seasonality.',\n",
    "        'Intuitive and works well for smoothly varying data.',\n",
    "        'Captures local trends and smooths short-term fluctuations.'\n",
    "    ],\n",
    "    'Cons': [\n",
    "        'Distorts distribution. Reduces variability in the dataset.',\n",
    "        'Can propagate outdated values for long stretches of missing data.',\n",
    "        'Computationally intensive. Sensitive to choice of K and distance metric.',\n",
    "        'Assumes consistent seasonal patterns. Complex to implement.',\n",
    "        'May not capture non-linear trends. Inaccurate for long gaps.',\n",
    "        'May miss sudden changes or long-term trends. Window size affects results.'\n",
    "    ],\n",
    "    'Best For': [\n",
    "        'States with limited data or random missing values.',\n",
    "        'States with consistent growth patterns and short gaps.',\n",
    "        'States with complex patterns and sufficient data from similar states.',\n",
    "        'States with clear yearly tourism patterns.',\n",
    "        'States with smooth, consistent trends between known data points.',\n",
    "        'States with local trends and short-term fluctuations.'\n",
    "    ],\n",
    "    'Example': [\n",
    "        \"Goa's missing 2018 data filled with average of available years.\",\n",
    "        \"Tamil Nadu's missing 2018 uses 2017 value (345,061,140).\",\n",
    "        \"Uses data from states with similar tourism patterns to impute.\",\n",
    "        \"Effective for states with clear yearly tourism cycles.\",\n",
    "        \"Estimates Uttarakhand's 2018 based on trend between 2017 and 2019.\",\n",
    "        \"Might use average of 2017 and 2019 to impute 2018 for a state.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison)\n",
    "df_comparison.set_index('Method', inplace=True)\n",
    "# print(df_comparison.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between imputation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Pros</th>\n",
       "      <th>Cons</th>\n",
       "      <th>Best For</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Imputation</th>\n",
       "      <td>Replaces missing values with the average of available data for each state.</td>\n",
       "      <td>Simple, quick to implement. Works for randomly missing data.</td>\n",
       "      <td>Distorts distribution. Reduces variability in the dataset.</td>\n",
       "      <td>States with limited data or random missing values.</td>\n",
       "      <td>Goa's missing 2018 data filled with average of available years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Fill</th>\n",
       "      <td>Fills missing values by using the last known value for each state.</td>\n",
       "      <td>Preserves trends. Simple to understand and implement.</td>\n",
       "      <td>Can propagate outdated values for long stretches of missing data.</td>\n",
       "      <td>States with consistent growth patterns and short gaps.</td>\n",
       "      <td>Tamil Nadu's missing 2018 uses 2017 value (345,061,140).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Imputation</th>\n",
       "      <td>Estimates missing values based on K most similar data points across states.</td>\n",
       "      <td>Captures complex patterns and multivariate relationships.</td>\n",
       "      <td>Computationally intensive. Sensitive to choice of K and distance metric.</td>\n",
       "      <td>States with complex patterns and sufficient data from similar states.</td>\n",
       "      <td>Uses data from states with similar tourism patterns to impute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seasonal Decomposition with Interpolation</th>\n",
       "      <td>Decomposes time series into trend, seasonal, and residual components, then interpolates.</td>\n",
       "      <td>Effective for data with clear seasonality.</td>\n",
       "      <td>Assumes consistent seasonal patterns. Complex to implement.</td>\n",
       "      <td>States with clear yearly tourism patterns.</td>\n",
       "      <td>Effective for states with clear yearly tourism cycles.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Interpolation</th>\n",
       "      <td>Assumes a linear relationship between known data points to estimate missing values.</td>\n",
       "      <td>Intuitive and works well for smoothly varying data.</td>\n",
       "      <td>May not capture non-linear trends. Inaccurate for long gaps.</td>\n",
       "      <td>States with smooth, consistent trends between known data points.</td>\n",
       "      <td>Estimates Uttarakhand's 2018 based on trend between 2017 and 2019.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time-Series Imputation with Rolling Mean</th>\n",
       "      <td>Uses a moving average of nearby time points to fill in missing values.</td>\n",
       "      <td>Captures local trends and smooths short-term fluctuations.</td>\n",
       "      <td>May miss sudden changes or long-term trends. Window size affects results.</td>\n",
       "      <td>States with local trends and short-term fluctuations.</td>\n",
       "      <td>Might use average of 2017 and 2019 to impute 2018 for a state.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                        Explanation  \\\n",
       "Method                                                                                                                                \n",
       "Mean Imputation                                          Replaces missing values with the average of available data for each state.   \n",
       "Forward Fill                                                     Fills missing values by using the last known value for each state.   \n",
       "KNN Imputation                                          Estimates missing values based on K most similar data points across states.   \n",
       "Seasonal Decomposition with Interpolation  Decomposes time series into trend, seasonal, and residual components, then interpolates.   \n",
       "Linear Interpolation                            Assumes a linear relationship between known data points to estimate missing values.   \n",
       "Time-Series Imputation with Rolling Mean                     Uses a moving average of nearby time points to fill in missing values.   \n",
       "\n",
       "                                                                                                   Pros  \\\n",
       "Method                                                                                                    \n",
       "Mean Imputation                            Simple, quick to implement. Works for randomly missing data.   \n",
       "Forward Fill                                      Preserves trends. Simple to understand and implement.   \n",
       "KNN Imputation                                Captures complex patterns and multivariate relationships.   \n",
       "Seasonal Decomposition with Interpolation                    Effective for data with clear seasonality.   \n",
       "Linear Interpolation                                Intuitive and works well for smoothly varying data.   \n",
       "Time-Series Imputation with Rolling Mean     Captures local trends and smooths short-term fluctuations.   \n",
       "\n",
       "                                                                                                                Cons  \\\n",
       "Method                                                                                                                 \n",
       "Mean Imputation                                           Distorts distribution. Reduces variability in the dataset.   \n",
       "Forward Fill                                       Can propagate outdated values for long stretches of missing data.   \n",
       "KNN Imputation                              Computationally intensive. Sensitive to choice of K and distance metric.   \n",
       "Seasonal Decomposition with Interpolation                Assumes consistent seasonal patterns. Complex to implement.   \n",
       "Linear Interpolation                                    May not capture non-linear trends. Inaccurate for long gaps.   \n",
       "Time-Series Imputation with Rolling Mean   May miss sudden changes or long-term trends. Window size affects results.   \n",
       "\n",
       "                                                                                                        Best For  \\\n",
       "Method                                                                                                             \n",
       "Mean Imputation                                               States with limited data or random missing values.   \n",
       "Forward Fill                                              States with consistent growth patterns and short gaps.   \n",
       "KNN Imputation                             States with complex patterns and sufficient data from similar states.   \n",
       "Seasonal Decomposition with Interpolation                             States with clear yearly tourism patterns.   \n",
       "Linear Interpolation                            States with smooth, consistent trends between known data points.   \n",
       "Time-Series Imputation with Rolling Mean                   States with local trends and short-term fluctuations.   \n",
       "\n",
       "                                                                                                      Example  \n",
       "Method                                                                                                         \n",
       "Mean Imputation                               Goa's missing 2018 data filled with average of available years.  \n",
       "Forward Fill                                         Tamil Nadu's missing 2018 uses 2017 value (345,061,140).  \n",
       "KNN Imputation                                 Uses data from states with similar tourism patterns to impute.  \n",
       "Seasonal Decomposition with Interpolation              Effective for states with clear yearly tourism cycles.  \n",
       "Linear Interpolation                       Estimates Uttarakhand's 2018 based on trend between 2017 and 2019.  \n",
       "Time-Series Imputation with Rolling Mean       Might use average of 2017 and 2019 to impute 2018 for a state.  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison.to_csv(\"4_df_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
